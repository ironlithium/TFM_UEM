{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX2ImjRXq2Bv",
        "outputId": "f613d6c1-dab3-4af0-ae20-62a2dffed7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv('/content/drive/MyDrive/neural_network/sentiment140_vader4_sinlematizar.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UftHWRT5rkLr",
        "outputId": "a4e5527e-f04b-4964-edc8-e9e214a810df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        polarity          id                          date     query  \\\n",
              "0       negative  2184288131  Mon Jun 15 15:41:28 PDT 2009  NO_QUERY   \n",
              "1       negative  1834602716  Mon May 18 03:33:33 PDT 2009  NO_QUERY   \n",
              "2       positive  1976167179  Sat May 30 16:44:04 PDT 2009  NO_QUERY   \n",
              "3       positive  2047727017  Fri Jun 05 14:05:11 PDT 2009  NO_QUERY   \n",
              "4       positive  2014391411  Wed Jun 03 01:22:32 PDT 2009  NO_QUERY   \n",
              "...          ...         ...                           ...       ...   \n",
              "121099  negative  2175983387  Mon Jun 15 02:34:22 PDT 2009  NO_QUERY   \n",
              "121100  positive  2185123417  Mon Jun 15 16:55:17 PDT 2009  NO_QUERY   \n",
              "121101  positive  1834315088  Mon May 18 02:27:47 PDT 2009  NO_QUERY   \n",
              "121102  positive  1676509898  Fri May 01 22:15:41 PDT 2009  NO_QUERY   \n",
              "121103  positive  2057368497  Sat Jun 06 12:52:29 PDT 2009  NO_QUERY   \n",
              "\n",
              "                   user                                               text  \\\n",
              "0                 Zelus  I want my e-mail with my tracking info for my ...   \n",
              "1                S810uk  Is not happy with the weather  I'm off to the ...   \n",
              "2       MicheleBlueston  @cindyscottday and forgot...you got kiddies ho...   \n",
              "3              adrian_x  @iota @brandie will ALWAYS be number two in MY...   \n",
              "4          muchloveanna   @cjmccoll no problem  gosh, her work is amazing!   \n",
              "...                 ...                                                ...   \n",
              "121099        zapakitul  Back from school!  Two more weeks of school he...   \n",
              "121100         dreacham  @lauren_nichelle i'll be sure to let daddy kno...   \n",
              "121101   Cherry_Gryffon  @erniehalter YAYYY new country invasion XD *do...   \n",
              "121102  tessthetraveler  just came back from op shopping in wynnum ther...   \n",
              "121103          RSG3191  @julesyog Cool, what time was that? I will loo...   \n",
              "\n",
              "        vader_polarity                                       preprocesado  \\\n",
              "0               0.0772                   want email track info new iphone   \n",
              "1              -0.4585  happy weather im museum later boy sock culture...   \n",
              "2               0.5106  forgotyou get kiddy home still free agent take...   \n",
              "3               0.0772                             always number two book   \n",
              "4               0.7469                            problem josh work amaze   \n",
              "...                ...                                                ...   \n",
              "121099         -0.6467        back school two week school hate highschool   \n",
              "121100          0.7639          ill sure let daddy know hell really happy   \n",
              "121101          0.6739              yyy new country invasion xd wi helmet   \n",
              "121102          0.6184  come back op shopping wynnum many 2nd hand sto...   \n",
              "121103          0.3182                                     cool time look   \n",
              "\n",
              "        word_count                          preprocesado_constopwords  label  \\\n",
              "0               12  i want my email with my track info for my new ...      0   \n",
              "1               27  is not happy with the weather im off to the mu...      0   \n",
              "2               16  and forgotyou get kiddy home still free agent ...      1   \n",
              "3                8                will always be number two in m book      1   \n",
              "4                7                  no problem josh her work be amaze      1   \n",
              "...            ...                                                ...    ...   \n",
              "121099          13  back from school two more week of school here ...      0   \n",
              "121100          11  ill be sure to let daddy know hell be really h...      1   \n",
              "121101           8          yyy new country invasion xd don wi helmet      1   \n",
              "121102          24  just come back from op shopping in wynnum ther...      1   \n",
              "121103          11     cool what time be that i will look out for you      1   \n",
              "\n",
              "                                preprocesado_sinlematizar  \n",
              "0       i want my email with my tracking info for my n...  \n",
              "1       is not happy with the weather im off to the mu...  \n",
              "2       and forgotyou got kiddies home still free agen...  \n",
              "3                     will always be number two in m book  \n",
              "4                     no problem josh her work is amazing  \n",
              "...                                                   ...  \n",
              "121099  back from school two more weeks of school here...  \n",
              "121100  ill be sure to let daddy know hell be really h...  \n",
              "121101         yyy new country invasion xd dons wi helmet  \n",
              "121102  just came back from op shopping in wynnum ther...  \n",
              "121103    cool what time was that i will look out for you  \n",
              "\n",
              "[121104 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cd7e41d-7af4-4449-846b-3b7aff624442\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>vader_polarity</th>\n",
              "      <th>preprocesado</th>\n",
              "      <th>word_count</th>\n",
              "      <th>preprocesado_constopwords</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocesado_sinlematizar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>2184288131</td>\n",
              "      <td>Mon Jun 15 15:41:28 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Zelus</td>\n",
              "      <td>I want my e-mail with my tracking info for my ...</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>want email track info new iphone</td>\n",
              "      <td>12</td>\n",
              "      <td>i want my email with my track info for my new ...</td>\n",
              "      <td>0</td>\n",
              "      <td>i want my email with my tracking info for my n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>1834602716</td>\n",
              "      <td>Mon May 18 03:33:33 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>S810uk</td>\n",
              "      <td>Is not happy with the weather  I'm off to the ...</td>\n",
              "      <td>-0.4585</td>\n",
              "      <td>happy weather im museum later boy sock culture...</td>\n",
              "      <td>27</td>\n",
              "      <td>is not happy with the weather im off to the mu...</td>\n",
              "      <td>0</td>\n",
              "      <td>is not happy with the weather im off to the mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>1976167179</td>\n",
              "      <td>Sat May 30 16:44:04 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>MicheleBlueston</td>\n",
              "      <td>@cindyscottday and forgot...you got kiddies ho...</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>forgotyou get kiddy home still free agent take...</td>\n",
              "      <td>16</td>\n",
              "      <td>and forgotyou get kiddy home still free agent ...</td>\n",
              "      <td>1</td>\n",
              "      <td>and forgotyou got kiddies home still free agen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>2047727017</td>\n",
              "      <td>Fri Jun 05 14:05:11 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>adrian_x</td>\n",
              "      <td>@iota @brandie will ALWAYS be number two in MY...</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>always number two book</td>\n",
              "      <td>8</td>\n",
              "      <td>will always be number two in m book</td>\n",
              "      <td>1</td>\n",
              "      <td>will always be number two in m book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>2014391411</td>\n",
              "      <td>Wed Jun 03 01:22:32 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>muchloveanna</td>\n",
              "      <td>@cjmccoll no problem  gosh, her work is amazing!</td>\n",
              "      <td>0.7469</td>\n",
              "      <td>problem josh work amaze</td>\n",
              "      <td>7</td>\n",
              "      <td>no problem josh her work be amaze</td>\n",
              "      <td>1</td>\n",
              "      <td>no problem josh her work is amazing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121099</th>\n",
              "      <td>negative</td>\n",
              "      <td>2175983387</td>\n",
              "      <td>Mon Jun 15 02:34:22 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>zapakitul</td>\n",
              "      <td>Back from school!  Two more weeks of school he...</td>\n",
              "      <td>-0.6467</td>\n",
              "      <td>back school two week school hate highschool</td>\n",
              "      <td>13</td>\n",
              "      <td>back from school two more week of school here ...</td>\n",
              "      <td>0</td>\n",
              "      <td>back from school two more weeks of school here...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121100</th>\n",
              "      <td>positive</td>\n",
              "      <td>2185123417</td>\n",
              "      <td>Mon Jun 15 16:55:17 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>dreacham</td>\n",
              "      <td>@lauren_nichelle i'll be sure to let daddy kno...</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>ill sure let daddy know hell really happy</td>\n",
              "      <td>11</td>\n",
              "      <td>ill be sure to let daddy know hell be really h...</td>\n",
              "      <td>1</td>\n",
              "      <td>ill be sure to let daddy know hell be really h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121101</th>\n",
              "      <td>positive</td>\n",
              "      <td>1834315088</td>\n",
              "      <td>Mon May 18 02:27:47 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Cherry_Gryffon</td>\n",
              "      <td>@erniehalter YAYYY new country invasion XD *do...</td>\n",
              "      <td>0.6739</td>\n",
              "      <td>yyy new country invasion xd wi helmet</td>\n",
              "      <td>8</td>\n",
              "      <td>yyy new country invasion xd don wi helmet</td>\n",
              "      <td>1</td>\n",
              "      <td>yyy new country invasion xd dons wi helmet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121102</th>\n",
              "      <td>positive</td>\n",
              "      <td>1676509898</td>\n",
              "      <td>Fri May 01 22:15:41 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>tessthetraveler</td>\n",
              "      <td>just came back from op shopping in wynnum ther...</td>\n",
              "      <td>0.6184</td>\n",
              "      <td>come back op shopping wynnum many 2nd hand sto...</td>\n",
              "      <td>24</td>\n",
              "      <td>just come back from op shopping in wynnum ther...</td>\n",
              "      <td>1</td>\n",
              "      <td>just came back from op shopping in wynnum ther...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121103</th>\n",
              "      <td>positive</td>\n",
              "      <td>2057368497</td>\n",
              "      <td>Sat Jun 06 12:52:29 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RSG3191</td>\n",
              "      <td>@julesyog Cool, what time was that? I will loo...</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>cool time look</td>\n",
              "      <td>11</td>\n",
              "      <td>cool what time be that i will look out for you</td>\n",
              "      <td>1</td>\n",
              "      <td>cool what time was that i will look out for you</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121104 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cd7e41d-7af4-4449-846b-3b7aff624442')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2cd7e41d-7af4-4449-846b-3b7aff624442 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2cd7e41d-7af4-4449-846b-3b7aff624442');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da71e650-7716-4e82-b5a6-fb6160708716\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da71e650-7716-4e82-b5a6-fb6160708716')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da71e650-7716-4e82-b5a6-fb6160708716 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_61765086-d6d9-4932-a279-19b0ed56dad4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_61765086-d6d9-4932-a279-19b0ed56dad4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X = df['preprocesado_sinlematizar']\n",
        "y = df['label']\n",
        "\n",
        "# Primero dividimos en entrenamiento (80%) y prueba (20%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=34, stratify=y)\n",
        "\n",
        "# Luego dividimos el conjunto temporal en entrenamiento (80% de 80%) y validación (20% de 80%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=34, stratify=y_temp)\n"
      ],
      "metadata": {
        "id": "AasWHyq_sCVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embedding_matrix_x_train= np.load('/content/drive/MyDrive/neural_network/embeddings_matrix_validation.npy')"
      ],
      "metadata": {
        "id": "lzRAY90UrpMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Configuración de Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.astype(str))\n",
        "sequences = tokenizer.texts_to_sequences(X_train.astype(str))\n",
        "\n",
        "max_length = 25\n",
        "X_train_def = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "\n",
        "embedding_dim = 400\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index) + 1"
      ],
      "metadata": {
        "id": "7rpPfRY4rtWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0X5jcHFrvFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir X_test a secuencias numéricas\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test.astype(str))  # Convertir a secuencias\n",
        "X_test_def = pad_sequences(sequences_test, maxlen=max_length, padding='post')  # Asegurarse de que tengan la misma longitud que max_len\n",
        "\n",
        "# Convertir X_val a secuencias numéricas\n",
        "sequences_val = tokenizer.texts_to_sequences(X_val.astype(str))  # Convertir a secuencias\n",
        "X_val_def = pad_sequences(sequences_val, maxlen=max_length, padding='post')  # Asegurar la longitud adecuada\n"
      ],
      "metadata": {
        "id": "IZMU3dp_jKbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "lLw9JQhnkGY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hR01K3LlNzI",
        "outputId": "989edf38-840a-47b1-e769-42fef57e682c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.7520 - loss: 0.4862 - val_accuracy: 0.8284 - val_loss: 0.3734\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.3755 - val_accuracy: 0.8410 - val_loss: 0.3589\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.3460 - val_accuracy: 0.8479 - val_loss: 0.3390\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.3288 - val_accuracy: 0.8519 - val_loss: 0.3316\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.3133 - val_accuracy: 0.8543 - val_loss: 0.3374\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8675 - loss: 0.2993 - val_accuracy: 0.8540 - val_loss: 0.3327\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8722 - loss: 0.2898 - val_accuracy: 0.8579 - val_loss: 0.3256\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8796 - loss: 0.2756 - val_accuracy: 0.8578 - val_loss: 0.3296\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.2665 - val_accuracy: 0.8574 - val_loss: 0.3305\n",
            "Epoch 10/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8870 - loss: 0.2572 - val_accuracy: 0.8570 - val_loss: 0.3387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_def = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C92d84SmGlP",
        "outputId": "0ca5c3d5-991d-4780-dbcc-964e88448373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3274\n",
            "Pérdida en el conjunto de test: 0.3289847671985626\n",
            "Precisión en el conjunto de test: 0.8565707206726074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDoXk2X1mGol",
        "outputId": "dc59f843-e8f0-4430-8bd3-213949dc962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7379 - loss: 0.4985 - val_accuracy: 0.8283 - val_loss: 0.3745\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.3805 - val_accuracy: 0.8373 - val_loss: 0.3618\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 0.3516 - val_accuracy: 0.8493 - val_loss: 0.3405\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.3358 - val_accuracy: 0.8532 - val_loss: 0.3308\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8575 - loss: 0.3208 - val_accuracy: 0.8559 - val_loss: 0.3423\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8646 - loss: 0.3076 - val_accuracy: 0.8595 - val_loss: 0.3309\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8704 - loss: 0.2978 - val_accuracy: 0.8622 - val_loss: 0.3214\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.8748 - loss: 0.2866 - val_accuracy: 0.8606 - val_loss: 0.3280\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8793 - loss: 0.2772 - val_accuracy: 0.8610 - val_loss: 0.3320\n",
            "Epoch 10/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8834 - loss: 0.2681 - val_accuracy: 0.8601 - val_loss: 0.3441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_def = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr4ZCxJFlN2e",
        "outputId": "f793bbef-4932-4b45-bc94-e8cab9612b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3240\n",
            "Pérdida en el conjunto de test: 0.3242965340614319\n",
            "Precisión en el conjunto de test: 0.8592130541801453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re3dDKAZqY4U",
        "outputId": "080af415-b297-4ade-d142-958e23c16da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7432 - loss: 0.4929 - val_accuracy: 0.8303 - val_loss: 0.3725\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.3787 - val_accuracy: 0.8398 - val_loss: 0.3608\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3485 - val_accuracy: 0.8490 - val_loss: 0.3420\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.3318 - val_accuracy: 0.8546 - val_loss: 0.3313\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.3165 - val_accuracy: 0.8537 - val_loss: 0.3488\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8673 - loss: 0.3036 - val_accuracy: 0.8607 - val_loss: 0.3315\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8719 - loss: 0.2926 - val_accuracy: 0.8606 - val_loss: 0.3292\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8768 - loss: 0.2805 - val_accuracy: 0.8607 - val_loss: 0.3338\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.2706 - val_accuracy: 0.8598 - val_loss: 0.3406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_def = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VSamKRYqY6A",
        "outputId": "09986b99-4a30-4bf2-d517-6545d622c21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.3301\n",
            "Pérdida en el conjunto de test: 0.33220455050468445\n",
            "Precisión en el conjunto de test: 0.858511209487915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUWq0PC6qY8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dY49jVD8qY_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HED9k5TgCbDy",
        "outputId": "e572785d-dbd3-4855-a474-c893f2690b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.4966 - val_accuracy: 0.8276 - val_loss: 0.3782\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8247 - loss: 0.3809 - val_accuracy: 0.8387 - val_loss: 0.3608\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.3519 - val_accuracy: 0.8464 - val_loss: 0.3400\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.3345 - val_accuracy: 0.8505 - val_loss: 0.3325\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8591 - loss: 0.3188 - val_accuracy: 0.8553 - val_loss: 0.3347\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8661 - loss: 0.3059 - val_accuracy: 0.8580 - val_loss: 0.3275\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.2954 - val_accuracy: 0.8591 - val_loss: 0.3227\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.2818 - val_accuracy: 0.8585 - val_loss: 0.3255\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8807 - loss: 0.2727 - val_accuracy: 0.8605 - val_loss: 0.3300\n",
            "Epoch 10/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8865 - loss: 0.2643 - val_accuracy: 0.8583 - val_loss: 0.3404\n",
            "Epoch 11/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.2573 - val_accuracy: 0.8603 - val_loss: 0.3524\n",
            "Epoch 12/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8954 - loss: 0.2451 - val_accuracy: 0.8595 - val_loss: 0.3659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_def = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiALGNFtCbGZ",
        "outputId": "daf6ba48-8400-4d26-c974-fc5c4a2ec1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3308\n",
            "Pérdida en el conjunto de test: 0.3299297094345093\n",
            "Precisión en el conjunto de test: 0.8588002324104309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVSiQ_dxFPD6",
        "outputId": "08581ded-bf9e-44a0-fd6a-1353f281b81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7561 - loss: 0.4857 - val_accuracy: 0.8307 - val_loss: 0.3727\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.3773 - val_accuracy: 0.8427 - val_loss: 0.3602\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.3456 - val_accuracy: 0.8516 - val_loss: 0.3345\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.3274 - val_accuracy: 0.8548 - val_loss: 0.3281\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.3106 - val_accuracy: 0.8543 - val_loss: 0.3526\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.2961 - val_accuracy: 0.8588 - val_loss: 0.3307\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.2819 - val_accuracy: 0.8566 - val_loss: 0.3345\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8851 - loss: 0.2659 - val_accuracy: 0.8595 - val_loss: 0.3429\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8931 - loss: 0.2504 - val_accuracy: 0.8585 - val_loss: 0.3446\n",
            "Epoch 10/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.2389 - val_accuracy: 0.8570 - val_loss: 0.3606\n",
            "Epoch 11/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.9043 - loss: 0.2251 - val_accuracy: 0.8590 - val_loss: 0.3902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAF1nSOfDsXn",
        "outputId": "3ccc1585-3d87-4355-a682-8166d6585d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3435\n",
            "Pérdida en el conjunto de test: 0.3441172242164612\n",
            "Precisión en el conjunto de test: 0.8578506112098694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h38RQMMt1D-",
        "outputId": "380812aa-88be-4fdb-c8ce-5e92a17bee59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.4867 - val_accuracy: 0.8355 - val_loss: 0.3667\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.8289 - loss: 0.3741 - val_accuracy: 0.8453 - val_loss: 0.3552\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8464 - loss: 0.3426 - val_accuracy: 0.8559 - val_loss: 0.3296\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.3219 - val_accuracy: 0.8582 - val_loss: 0.3296\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.3032 - val_accuracy: 0.8610 - val_loss: 0.3516\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8755 - loss: 0.2846 - val_accuracy: 0.8607 - val_loss: 0.3441\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8849 - loss: 0.2656 - val_accuracy: 0.8570 - val_loss: 0.3390\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.8950 - loss: 0.2456 - val_accuracy: 0.8548 - val_loss: 0.3874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxR6rhL3t1HE",
        "outputId": "55466873-a07d-455f-e640-368cc6d78d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3562\n",
            "Pérdida en el conjunto de test: 0.35788002610206604\n",
            "Precisión en el conjunto de test: 0.8581396341323853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzqx9gEuUqq",
        "outputId": "b0d1c7b6-e9f3-40e3-d099-40211edc703a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.4785 - val_accuracy: 0.8319 - val_loss: 0.3706\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8275 - loss: 0.3752 - val_accuracy: 0.8432 - val_loss: 0.3601\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8467 - loss: 0.3422 - val_accuracy: 0.8493 - val_loss: 0.3385\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8562 - loss: 0.3232 - val_accuracy: 0.8557 - val_loss: 0.3331\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8662 - loss: 0.3050 - val_accuracy: 0.8572 - val_loss: 0.3535\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8764 - loss: 0.2887 - val_accuracy: 0.8578 - val_loss: 0.3362\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8814 - loss: 0.2725 - val_accuracy: 0.8553 - val_loss: 0.3413\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8894 - loss: 0.2580 - val_accuracy: 0.8550 - val_loss: 0.3594\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.8976 - loss: 0.2433 - val_accuracy: 0.8578 - val_loss: 0.3497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voSypmm5uUuP",
        "outputId": "f94a0d4b-406d-4f57-b844-fc9904628007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 0.3334\n",
            "Pérdida en el conjunto de test: 0.33592358231544495\n",
            "Precisión en el conjunto de test: 0.8574790358543396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRuk1AAQuTx9",
        "outputId": "6640f579-b210-4dd6-9432-9b61cb4d850c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - accuracy: 0.7435 - loss: 0.4955 - val_accuracy: 0.8276 - val_loss: 0.3737\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.3758 - val_accuracy: 0.8392 - val_loss: 0.3654\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.3469 - val_accuracy: 0.8495 - val_loss: 0.3424\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8515 - loss: 0.3300 - val_accuracy: 0.8542 - val_loss: 0.3285\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8625 - loss: 0.3135 - val_accuracy: 0.8586 - val_loss: 0.3316\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8687 - loss: 0.3008 - val_accuracy: 0.8605 - val_loss: 0.3275\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8735 - loss: 0.2902 - val_accuracy: 0.8606 - val_loss: 0.3296\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8785 - loss: 0.2783 - val_accuracy: 0.8602 - val_loss: 0.3280\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8847 - loss: 0.2690 - val_accuracy: 0.8615 - val_loss: 0.3404\n",
            "Epoch 10/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8880 - loss: 0.2597 - val_accuracy: 0.8560 - val_loss: 0.3477\n",
            "Epoch 11/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8907 - loss: 0.2536 - val_accuracy: 0.8583 - val_loss: 0.3587\n",
            "Epoch 12/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8962 - loss: 0.2423 - val_accuracy: 0.8580 - val_loss: 0.3611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ_mOpwmwCtc",
        "outputId": "33289b85-50c6-46f4-cce9-320abb675564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.3393\n",
            "Pérdida en el conjunto de test: 0.3404638171195984\n",
            "Precisión en el conjunto de test: 0.8583047986030579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRpTBIgowFth",
        "outputId": "113a4f46-e476-4b39-a836-bd690a01e085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - accuracy: 0.7559 - loss: 0.4848 - val_accuracy: 0.8332 - val_loss: 0.3678\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.8267 - loss: 0.3755 - val_accuracy: 0.8453 - val_loss: 0.3574\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8445 - loss: 0.3429 - val_accuracy: 0.8510 - val_loss: 0.3367\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8562 - loss: 0.3238 - val_accuracy: 0.8548 - val_loss: 0.3284\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8656 - loss: 0.3054 - val_accuracy: 0.8564 - val_loss: 0.3482\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8745 - loss: 0.2895 - val_accuracy: 0.8572 - val_loss: 0.3348\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8799 - loss: 0.2751 - val_accuracy: 0.8528 - val_loss: 0.3391\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.2584 - val_accuracy: 0.8554 - val_loss: 0.3562\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8983 - loss: 0.2399 - val_accuracy: 0.8525 - val_loss: 0.3574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkRb2vSKx3AC",
        "outputId": "1346911b-0f31-41d1-f3bf-09aba839e618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3321\n",
            "Pérdida en el conjunto de test: 0.33397775888442993\n",
            "Precisión en el conjunto de test: 0.8552082777023315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n76RKwcryDTY",
        "outputId": "177774eb-beac-436b-93c4-ec2d60c75dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7632 - loss: 0.4785 - val_accuracy: 0.8349 - val_loss: 0.3703\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.8291 - loss: 0.3736 - val_accuracy: 0.8486 - val_loss: 0.3504\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.3406 - val_accuracy: 0.8562 - val_loss: 0.3324\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8586 - loss: 0.3197 - val_accuracy: 0.8581 - val_loss: 0.3346\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8682 - loss: 0.2987 - val_accuracy: 0.8558 - val_loss: 0.3468\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8797 - loss: 0.2802 - val_accuracy: 0.8559 - val_loss: 0.3585\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8902 - loss: 0.2585 - val_accuracy: 0.8535 - val_loss: 0.3681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0vS35OiyPKN",
        "outputId": "67f16f1e-b783-4fee-e94b-f90c0fa77231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.3358\n",
            "Pérdida en el conjunto de test: 0.33671441674232483\n",
            "Precisión en el conjunto de test: 0.855167031288147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUMLEJkEyQyz",
        "outputId": "1fcc67cd-651a-4182-b35c-e08ada99f4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7590 - loss: 0.4836 - val_accuracy: 0.8344 - val_loss: 0.3686\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.8294 - loss: 0.3738 - val_accuracy: 0.8473 - val_loss: 0.3543\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8475 - loss: 0.3397 - val_accuracy: 0.8540 - val_loss: 0.3348\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8583 - loss: 0.3192 - val_accuracy: 0.8559 - val_loss: 0.3369\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8707 - loss: 0.2989 - val_accuracy: 0.8579 - val_loss: 0.3502\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.2780 - val_accuracy: 0.8585 - val_loss: 0.3535\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8902 - loss: 0.2579 - val_accuracy: 0.8556 - val_loss: 0.3570\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9009 - loss: 0.2347 - val_accuracy: 0.8556 - val_loss: 0.4094\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9102 - loss: 0.2133 - val_accuracy: 0.8543 - val_loss: 0.3797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XLDOsApyVGb",
        "outputId": "3cb5faed-5b67-4b65-810b-68f35eca59f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3554\n",
            "Pérdida en el conjunto de test: 0.3548884689807892\n",
            "Precisión en el conjunto de test: 0.8569010496139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Parámetros\n",
        "max_len = X_train_def.shape[1]\n",
        "seed=42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix_x_train], trainable=False, input_length=max_len))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0005)  # Reducir el learning rate\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) # Función de pérdida binaria\n",
        "\n",
        "# Definir Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Entrenamiento con Early Stopping usando conjuntos de validación específicos\n",
        "history = model.fit(\n",
        "    X_train_def, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_def, y_val),  # Especifica los conjuntos de validación\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8hfWxwSyWm_",
        "outputId": "d58acc2c-e2c2-4a43-d84b-dc05a2c190cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.4865 - val_accuracy: 0.8280 - val_loss: 0.3767\n",
            "Epoch 2/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8264 - loss: 0.3756 - val_accuracy: 0.8410 - val_loss: 0.3599\n",
            "Epoch 3/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8451 - loss: 0.3447 - val_accuracy: 0.8497 - val_loss: 0.3414\n",
            "Epoch 4/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8565 - loss: 0.3251 - val_accuracy: 0.8533 - val_loss: 0.3358\n",
            "Epoch 5/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.8660 - loss: 0.3069 - val_accuracy: 0.8591 - val_loss: 0.3470\n",
            "Epoch 6/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8748 - loss: 0.2913 - val_accuracy: 0.8593 - val_loss: 0.3302\n",
            "Epoch 7/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8816 - loss: 0.2750 - val_accuracy: 0.8557 - val_loss: 0.3344\n",
            "Epoch 8/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8883 - loss: 0.2588 - val_accuracy: 0.8577 - val_loss: 0.3714\n",
            "Epoch 9/20\n",
            "\u001b[1m2423/2423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8969 - loss: 0.2430 - val_accuracy: 0.8577 - val_loss: 0.3520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluación en el conjunto de test\n",
        "test_loss, test_accuracy = model.evaluate(X_test_def, y_test, batch_size=64)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de test: {test_loss}\")\n",
        "print(f\"Precisión en el conjunto de test: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYmY5PIVyYeN",
        "outputId": "1a10ddff-10ee-40d2-8fff-1a109035d647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3313\n",
            "Pérdida en el conjunto de test: 0.33376309275627136\n",
            "Precisión en el conjunto de test: 0.8557863235473633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3oJyUxbuyhGz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}